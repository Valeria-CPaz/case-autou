üõë Limita√ß√µes encontradas e decis√µes de arquitetura

Durante o desenvolvimento da solu√ß√£o, foi realizado um estudo e teste pr√°tico de diversas abordagens para integra√ß√£o de IA, visando classificar e-mails e sugerir respostas autom√°ticas:

1. Tentativas com APIs de IA externas

Foram testadas as seguintes alternativas:

OpenAI GPT (gpt-3.5-turbo):

Problema: Todas as contas gratuitas testadas atingiram o limite de quota, impedindo o uso durante o desenvolvimento e deploy.

Impacto: Qualquer usu√°rio/avaliador que tentar rodar a API sem chave paga receber√° erro de quota (‚ÄúYou exceeded your current quota...‚Äù).

Google Gemini (API generativeai):

Problema: Limite de quota free extremamente baixo, impossibilitando uso est√°vel at√© mesmo para prot√≥tipos ou testes simples.

Impacto: Falha com erro 429 (‚Äúquota exceeded‚Äù) mesmo em contas novas.

Hugging Face Inference API:

Problema: Modelos p√∫blicos frequentemente ficam fora do ar, retornam 404 ou erros internos (‚Äúindex out of range‚Äù).
Modelos PT-BR de classifica√ß√£o, sentiment analysis ou spam detection testados estavam todos indispon√≠veis no momento do desenvolvimento (julho/2025).

Impacto: N√£o h√° garantia de funcionamento, mesmo para projetos de MVP/demo.
Al√©m disso, a quota free √© muito baixa e pode ser consumida rapidamente.

2. Pipeline local com Transformers

Vantagem:
Permite rodar modelos robustos (como BERT ou Bertweet) localmente, sem depender de quota ou de disponibilidade online.
N√£o h√° limite de uso, funciona offline e √© ideal para demonstra√ß√µes locais.

Limita√ß√£o:
A maioria das plataformas de nuvem gratuita (Render, Vercel, Heroku Free, etc) n√£o permite baixar modelos grandes (~400MB+) ou executar tarefas pesadas de IA devido √† limita√ß√£o de RAM, CPU e armazenamento.
Com isso, o deploy p√∫blico pode n√£o rodar a IA local ‚Äî apenas ambientes locais de desenvolvimento.

3. Solu√ß√£o adotada para garantir robustez

A arquitetura do sistema foi desenhada para ser plug-and-play:

Toda a integra√ß√£o com IA (OpenAI, Gemini, Hugging Face) est√° pronta, documentada e testada, bastando descomentar e inserir a chave.

Para garantir estabilidade e evitar bloqueios no deploy p√∫blico, a vers√£o principal do sistema utiliza classifica√ß√£o local baseada em palavras-chave, sempre funcionando para qualquer usu√°rio, sem depend√™ncia de quota ou APIs externas.

Caso seja necess√°rio rodar IA de verdade, basta seguir a documenta√ß√£o do arquivo external_apis.py e executar localmente.

Resumo:
A decis√£o foi priorizar robustez e experi√™ncia do usu√°rio, evitando travamentos causados por limita√ß√£o de quota gratuita das APIs p√∫blicas.
A arquitetura segue pronta para integra√ß√£o real de IA assim que o ambiente e recursos estiverem dispon√≠veis!